# Pytorch使用说明    
## <font color = green>要点说明</font>
### <font color = purple>1.全局问题 </font> 
```
import torch  # 引入Pytorch库
print(torch.cuda.is_available())  # 测试GPU是否有效
```  
上述代码如果执行后，如果输出True，那么表明开发环境一切正常。   
```
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  
```
本语句表示当前代码将会在第一个GPU上运行。  

### <font color = purple>2.基本Pytorch操作 </font>   
#### 2.1张量 
与numpy数据转化：  
```
torch.from_numpy(numpy_data)   
torch.tensor(numpt_data)   
```
形状操作：
```
import torch
x = torch.rand(2,1)  # 定义一个张量
print(x.shape)  # 打印张量形状，输出:torch.Size([2,1])
print(x.size())  # 打印张量大小，输出:torch.Size([2, 1])
print(x.reshape([1,2]).shape)  # 先将张量的形状重新塑造，然后打印张量的形状，输出:torch.Size([1, 2])
```  
随机数操作：  
```
import torch
torch.manual_seed(2)  # 设置随机数种子  
torch.initial_seed()  # 查看随机数种子，输出:2
torch.randn(2,3)  # 随机生成指定形状的随机值张量
torch.arange(1,10,step=2)  # 在1到10之间，按照步长为2进行取值，输出:tensor([1,3,5,7,9])
torch.linspace(1,9,steps=5)  # 在1到9之间，均匀地取出5个值，输出:tensor([1.,3.,5.,7.,9.])
torch.empty(1,2)  # 按照指定形状生成未初始化的矩阵
```  

张量间的计算：  
```
import torch
a = torch.FloatTensor([4])
b = torch.add(a,a)  # 调用torch.add()进行相加
torch.add(a,a,out=b)  # 调用torch.add()进行相加，并且将结果输出给b
a.add_(b)  # 实现 a+=b
```
reshape操作，-1来代表维度由系统自动计算  
```
a = torch.tensor([[1,2],[3,4]])
print(torch.reshape(a,(1,-1)).shape)  
b = torch.tensor([[5,6,7],[2,8,0]])
torch.t(b)  # 转置矩阵
torch.transpose(b,dim0=1,dim1=0)  # 转置矩阵
b.permute(1,0)  # 将矩阵的第0维度与第1维度交换
a = torch.tensor([[1,2,3],[4,5,6]])
print(torch.cat([a,b],dim=0))  # 输出:tensor([[1, 2, 3],[4, 5, 6],[5, 6, 7],[2, 8, 0]])
print(torch.cat([a,b],dim=1))  # 输出:tensor([[1, 2, 3, 5, 6, 7],[4, 5, 6, 2, 8, 0]])
torch.chunk(a,chunks=2,dim=0)  # 将张量a沿着第0维度分割成2部分,返回类型是tuple
torch.chunk(a,chunks=2,dim=1)  # 将张量a沿着第1维度分割成2部分,返回类型是tuple
b = torch.tensor([[5,6,7],[2,8,0]])  # 定义一个二维张量
torch.split(b,split_size_or_sections=(1,2),dim =1)  # 将张量b沿着第1维度分割成两个部分
                                                    # 输出:(tensor([[5],[2]]),tensor([[6, 7],[8, 0]]))
torch.split(b,split_size_or_sections=2,dim =1)  # 将张量b沿着第1维度分割成2部分，每部分按照2个元素进行拆分。不满足指定个数的剩余数据，将会被作为分割数据的最后一部分
torch.gather(b,dim=1,index=torch.tensor([[1,0],[1,2]]))  # 沿着第1维度，按照index的形状进行取值排列。输出tensor([[6, 5],[8, 0]])
torch.index_select(b,dim=0,index=torch.tensor(1))  # 沿着第0维度,取出第一个元素,输出:tensor([[2, 8, 0]])
```   
  

#### 2.2 Variable类型与自动微分模块    
Variable是Pytorch中的一个变量类型，是由Autograd模块对张量进一步封装实现的。一旦张量(Tensor)被转化为Variable对象，便可以实现自动求导的功能。  
Autograd，自动微分模块是构成神经网络训练的必要模块。主要是在神经网络的反向传播过程中，基于正向计算的结果对当前参数进行微分计算，从而实现网络权重的更新。   
注意在使用requires_grad时，要求张量的类型必须是浮点型。Pytorch不支持整型做梯度运算。  
```
import torch
from torch.autograd import Variable
a = torch.FloatTensor([4])  # 定义张量a
print(Variable(a))  # 把张量a转化为Variable对象，输出:tensor([4.])
print(Variable(a,requires_grad=True))  # 把张量a转化为支持梯度计算的Variable对象，输出:tensor([4.], requires_grad=True)
print(a.data)  # Variable对象转化为张量，输出:tensor([4.])
```   
no_grad()函数，顾名思义，可以终止局部的梯度计算。  
```
import torch
from torch.autograd import Variable
x = torch.ones(2,2,requires_grad=True)
with torch.no_grad():  # 使用本函数限制requires_grad的作用域
    y = x * 2
z = x * 2
print(z.requires_grad)  # 输出:True
print(y.requires_grad)  # 输出:Flase
@torch.no_grad()
def doubler(x):
    return x * 2
z = doubler(x)
print(z.requires_grad)  # 输出:False
torch.set_grad_enabled(True)  # 全局统一打开/关闭梯度计算功能
```  
当带有需求梯度计算的张量经过一系列的计算最终生成一个标量，便可以使用该标量的backward()方法进行自动求导。该方法会自动调用每个需要求导变量的grad_fn()函数，并且将结果放到该变量的grad属性中。   
backward()方法一定要在当前变量内容是标量的情况下使用，否则会报错。 
```
import torch
x = torch.ones(2,2,requires_grad=True)  # 定义一个Variable对象，并且打开梯度计算
m = x + 2  # 通过计算得到了m变量
f = m.mean()  # 通过m的mean()方法，得到了一个标量
f.backward()  # 调用标量的backward()进行自动求导
print(f,x.grad)
```    
需要求梯度的Variable对象无法被直接转化为Numpy对象。这个时候可以使用detach()方法，可以将Variable从创建它的图中分离出来，该代码会创建一个新的、从当前图中分离的Variable，并且把它作为叶子节点。被返回的Variable和被分离的Variable指向同一个张量，并且永远不会需要梯度。  
实际使用中，可以使用detach()方法实现对网络中的部分参数求梯度的功能。 


### <font color = purple>3.定义网络模型 </font>   
定义神经网络模型可以分为以下几个步骤：   
(1)定义网络模型类，使其继承与Module类；  
(2)在网络模型类的初始化接口中定义网络层；  
(3)在网络模型类的正向传播接口中，将网络层连接起来，并且添加激活函数，搭建网络结构。  


#### 3.1 多层全连接神经网络的模型构建  
首先是需要生成模型，可以通过继承nn.Module类来生成我们的模型。  
其中，初始函数(__init__)是用来初始化网络的结构，该函数中定义了两个全连接层和一个交叉熵函数；forward函数规定了本模型的正向传播算法；predict函数规定了本模型的预测算法；getloss函数实现了本模型的loss值的计算。    
```
import torch.nn as nn
import torch
import numpy as np
import matplotlib.pyplot as plt
class LogicNet(nn.Module):  #继承nn.Module类，构建网络模型
    def __init__(self,inputdim,hiddendim,outputdim):  # 初始化函数中确定网络结构
        super(LogicNet,self).__init__()
        self.Linear1 = nn.Linear(inputdim,hiddendim)  # 定义全连接层
        self.Linear2 = nn.Linear(hiddendim,outputdim)  # 定义全连接层
        self.criterion = nn.CrossEntropyLoss()  # 定义交叉熵函数
    
    def forward(self,x):  # 搭建网络模型
        x = self.Linear1(x)  # 将输入数据传入第1搁全连接层
        x = torch.tanh(x)  # 对第1个连接层的结果进行非线性变换（使用tanh函数）
        x = self.Linear2(x)  # 将完成了非线性变换后的数据传入第二个连接层
        return x  # 输出第二个连接层的结果
    
    def predict(self,x):  # 实现LogicNet类的预测接口
        # 调用自身网络模型，并且对结果进行softmax处理，分别得出预测数据中属于每一类的概率
        x = self.forward(x)  # 调用自身网络模型，将结果赋到x中
        pred = torch.softmax(x,dim=1)  # 返回每组预测概率中最大值的索引
    
    def getloss(self,x,y):  # 实现LogicNet类的损失值接口
        y_pred = self.forward(x)
        loss = self.criterion(y_pred,y)  # 计算损失值的交叉熵
        return loss
```
只需要将定义好的网络模型类进行实例化，即可真正地完成网络模型的搭建。同时，需要定义训练模型所需要的优化器，优化器会在训练模型的反向传播过程中使用。  
```
model = LogicNet(inputdim=2,hiddendim=3,outputdim=2)  # 实例化模型
optimizer = torch.optim.Adam(model.parameters(),lr=0.01)  # 定义优化器
```
在完成实例化模型和定义好优化器后，此时应该开始训练模型，神经网路的训练过程是一步步进行的，每一步的详细操作如下：  
(1)每次把数据传入到网络中，通过正向结构得到预测值。  
(2)把预测结果与目标间的误差作为损失。  
(3)利用反向求导的链式法则，求出神经网络中每一层的损失。  
(4)根据损失值对其当前网络层的权重参数进行求导，计算出每个参数的修正值，并且对该层网络中的参数进行更新。    
```
x = torch.from_numpy(feature_data).type(torch.FloatTensor)  # 将numpy数据转化为张量  
y = torch.from_numpy(target_data).type(torch.LongTensor)
epochs = 270  # 定义迭代次数
losses = list()  # 定义列表，用于接受每一步的损失值
for i in range(epochs):
    loss = model.getloss(x,y)  # 将数据带入模型进行计算，得到损失值
    losses.append(loss.item())  # 保留这一轮训练的损失值到losses中
    optimizer.zero_grad()  # 清空之前的梯度
    loss.backward()  # 反向传播损失值
    optimizer.step()  # 更新参数
```    
